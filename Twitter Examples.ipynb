{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tweepy Library and setup auth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "# import json\n",
    "consumer_key = \"YOUR_consumer_key\"\n",
    "consumer_secret = \"YOUR_consumer_secret\"\n",
    "access_token = \"YOUR_access_token\"\n",
    "access_token_secret = \"YOUR_access_token_secret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Your Timeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the API object to get tweets from your timeline, and storing it in a variable called public_tweets\n",
    "public_tweets = api.home_timeline(count=2)\n",
    "# foreach through all tweets pulled\n",
    "for tweet in public_tweets:\n",
    "   # printing the text stored inside the tweet object\n",
    "#     print(json.dumps(tweet._json))\n",
    "    print (tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Tweets from a Specific User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth)\n",
    "# The Twitter user who we want to get tweets from\n",
    "name = \"unimalaya\"\n",
    "# Number of tweets to pull\n",
    "tweetCount = 1\n",
    "# Calling the user_timeline function with our parameters\n",
    "results = api.user_timeline(id=name, count=tweetCount)\n",
    "# foreach through all tweets pulled\n",
    "for tweet in results:\n",
    "   # printing the text stored inside the tweet object\n",
    "   print (tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Finding Tweets Using a Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth)\n",
    "# The search term you want to find\n",
    "query = \"كأس العالم\"\n",
    "# Language code (follows ISO 639-1 standards)\n",
    "language = \"ar\"\n",
    "# Calling the user_timeline function with our parameters\n",
    "results = api.search(q=query,count=5, lang=language)\n",
    "# foreach through all tweets pulled\n",
    "for tweet in results:\n",
    "   # printing the text stored inside the tweet object\n",
    "   print ('user:',tweet.user.screen_name,'\\n',tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Tweets And cleaning data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object called 'customStreamListener'\n",
    "class CustomStreamListener(tweepy.StreamListener):\n",
    "\n",
    "    def on_status(self, status):\n",
    "        print (status.author.screen_name, status.created_at, status.text)\n",
    "        # Writing status data\n",
    "        with open('OutputStreaming.csv', 'a',encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([status.author.screen_name, status.created_at, status.text])\n",
    "\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print >> sys.stderr, 'Encountered error with status code:', status_code\n",
    "        return True # Don't kill the stream\n",
    "\n",
    "    def on_timeout(self):\n",
    "        print >> sys.stderr, 'Timeout...'\n",
    "        return True # Don't kill the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing csv titles\n",
    "with open('OutputStreaming.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Author', 'Date', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamingAPI = tweepy.streaming.Stream(auth, CustomStreamListener())\n",
    "streamingAPI.filter(track=['#Croatia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for tweet in api.user_timeline(id='lashuel', count=4):\n",
    "    result.append({\n",
    "        'text': tweet.text, \n",
    "        'author_name': tweet.user.screen_name\n",
    "    })\n",
    "with open('tweet.json', 'w+') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lashuel_tweets = pd.read_json('tweet.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lashuel_tweets.to_csv('tweet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antoher Example selecting fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_20_tweets_of_ArsenalFC = api.user_timeline('arsenal')\n",
    "\n",
    "my_list_of_dicts = []\n",
    "for each_json_tweet in last_20_tweets_of_ArsenalFC:\n",
    "    my_list_of_dicts.append(each_json_tweet._json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_json_Arsenal.json', 'w') as file:\n",
    "        file.write(json.dumps(my_list_of_dicts, indent=4))\n",
    "\n",
    "my_demo_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_json_Arsenal.json', encoding='utf-8') as json_file:  \n",
    "    all_data = json.load(json_file)\n",
    "    for each_dictionary in all_data:\n",
    "        tweet_id = each_dictionary['id']\n",
    "        text = each_dictionary['text']\n",
    "        favorite_count = each_dictionary['favorite_count']\n",
    "        retweet_count = each_dictionary['retweet_count']\n",
    "        created_at = each_dictionary['created_at']\n",
    "        my_demo_list.append({'tweet_id': str(tweet_id),\n",
    "                             'text': str(text),\n",
    "                             'favorite_count': int(favorite_count),\n",
    "                             'retweet_count': int(retweet_count),\n",
    "                             'created_at': created_at,\n",
    "                            })\n",
    "        #print(my_demo_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json = pd.DataFrame(my_demo_list, columns = \n",
    "                                  ['tweet_id', 'text', \n",
    "                                   'favorite_count', 'retweet_count', \n",
    "                                   'created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.to_pickle('arsenal_tweets.pkl.gz',compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.to_csv('arsenal_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data = pd.read_pickle('arsenal_tweets.pkl.gz',compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
